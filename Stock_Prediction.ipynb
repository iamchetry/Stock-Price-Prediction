{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stock_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP4NiSW8nL2NY1unpVu4ShO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamchetry/Stock-Price-Prediction/blob/main/Stock_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U9xSkQpge_d",
        "outputId": "9c276f43-192d-4d70-e3ac-3663af206463"
      },
      "source": [
        "!pip install yfinance\n",
        "!pip install pyspark\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from matplotlib.pyplot import *\n",
        "\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession, SQLContext\n",
        "from pyspark.ml.feature import StandardScaler, VectorAssembler, QuantileDiscretizer\n",
        "from pyspark.sql.functions import rand, lead, mean, stddev, col, udf, lit\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras import optimizers, regularizers\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.63.tar.gz (26 kB)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.6.3-cp37-cp37m-manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.63-py2.py3-none-any.whl size=23918 sha256=812440199f8ad0463e05f06fa406a521c755d2b6418beb2c2d1ef25a80483264\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/87/8b/7ec24486e001d3926537f5f7801f57a74d181be25b11157983\n",
            "Successfully built yfinance\n",
            "Installing collected packages: lxml, yfinance\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed lxml-4.6.3 yfinance-0.1.63\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 66 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 40.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=5efc05bf8bf49e281c257a2d1a920b872679576c2c7f4c4d22631c6ac1ec9c55\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm8xlmn6hIHj"
      },
      "source": [
        "# Spark Session\n",
        "\n",
        "conf = SparkConf().setAppName('Stock Price Prediction').setMaster('local[2]')\n",
        "sc = SparkContext(conf=conf)\n",
        "sql_context = SQLContext(sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBlDYl_LjHnR"
      },
      "source": [
        "# Fetch Stock data from Yahoo Finance\n",
        "\n",
        "def dump_stock_data(name=None):\n",
        "  msft = yf.Ticker(name)\n",
        "\n",
        "  df_hist = msft.history(period='max')\n",
        "  df_hist['date_'] = df_hist.index\n",
        "  df_hist.index = range(len(df_hist))\n",
        "\n",
        "  df_hist.to_csv('df_stock_hist.csv', index=False)\n",
        "  !mv df_stock_hist.csv '/content/drive/My Drive/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oePEbLtyuVtW"
      },
      "source": [
        "dump_stock_data(name='GOOGL')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTMK-KQBqqug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1d5a987-d3a2-4ff1-b73d-18f32bf49eb8"
      },
      "source": [
        "# Load Spark df\n",
        "\n",
        "df_hist = sql_context.read.csv('/content/drive/My Drive/df_stock_hist.csv', header=True, inferSchema=True)[['date_', 'Open']]\n",
        "df_hist.orderBy('date_', ascending=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[date_: string, Open: double]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BseP-OJ5C5uF"
      },
      "source": [
        "# Creating Lagged Features\n",
        "for _ in range(1, 61):\n",
        "  df_hist = df_hist.withColumn('Open_{}'.format(_), lead('Open', _).over(Window.orderBy('date_')))\n",
        "\n",
        "df_hist = df_hist.drop('date_')\n",
        "df_hist = df_hist.withColumnRenamed('Open_60', 'target_price').withColumnRenamed('Open', 'Open_0')\n",
        "df_hist = df_hist.na.drop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvarrYtUsLe6"
      },
      "source": [
        "# Train Test Split\n",
        "discretizer = QuantileDiscretizer(numBuckets=10, inputCol='target_price', outputCol='bins')\n",
        "\n",
        "df_hist = discretizer.fit(df_hist).transform(df_hist)\n",
        "df_hist.bins = df_hist.bins.astype('int')\n",
        "\n",
        "train = df_hist.sampleBy('bins', fractions={0: 0.8, 1: 0.8, 2: 0.8, 3: 0.8, 4: 0.8, 5: 0.8, 6: 0.8, 7: 0.8, 8: 0.8, 9: 0.8}, seed=10)\n",
        "test = df_hist.subtract(train)\n",
        "\n",
        "df_hist = df_hist.drop('bins')\n",
        "train = train.drop('bins')\n",
        "test = test.drop('bins')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npmqnNKUst94"
      },
      "source": [
        "# Calculate Mean and STD for each column in Train data\n",
        "mean_list = list()\n",
        "std_list = list()\n",
        "\n",
        "for col_ in train.columns:\n",
        "  df_stats = train.select(mean(col(col_)).alias('avg_{}'.format(col_)), stddev(col(col_)).alias('std_{}'.format(col_))).collect()\n",
        "  mean_list.append(df_stats[0]['avg_{}'.format(col_)])\n",
        "  std_list.append(df_stats[0]['std_{}'.format(col_)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZfF3elLkkOf"
      },
      "source": [
        "# Scale Data\n",
        "def z_score(x, mean_, std_):\n",
        "  return (x - mean_)/std_\n",
        "\n",
        "scale_ = udf(lambda x, mean_, std_: z_score(x, mean_, std_), DoubleType())\n",
        "\n",
        "for _, col_ in enumerate(list(df_hist.columns)):\n",
        "  mean_ = mean_list[_]\n",
        "  std_ = std_list[_]\n",
        "\n",
        "  train = train.withColumn(col_+'_scaled', scale_(df_hist[col_], lit(mean_), lit(std_)))\n",
        "  test = test.withColumn(col_+'_scaled', scale_(df_hist[col_], lit(mean_), lit(std_)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQBMdLmnlBrp"
      },
      "source": [
        "# Create Feature Vector and Target Variable\n",
        "assembler = VectorAssembler(inputCols=['Open_{}_scaled'.format(_) for _ in range(60)], outputCol='features')\n",
        "\n",
        "train = assembler.transform(train).select(['features', 'target_price_scaled'])\n",
        "test = assembler.transform(test).select(['features', 'target_price_scaled'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R63SCng4mjKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d009fb-2ee8-4743-840d-faf5f909329d"
      },
      "source": [
        "test.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+\n",
            "|            features|target_price_scaled|\n",
            "+--------------------+-------------------+\n",
            "|[-1.1303337538563...|  -1.00878975315894|\n",
            "|[-1.1198932345828...| -1.019233606609437|\n",
            "|[-1.1230978528307...| -1.023391057709735|\n",
            "|[-1.1321912093307...|-1.0088719862513797|\n",
            "|[-1.1306093112925...| -1.009292302652219|\n",
            "|[-1.1245981065259...|-1.0128558202281577|\n",
            "|[-1.0959912620022...|-0.9973499377321561|\n",
            "|[-1.0918477182529...|-0.9896472430764616|\n",
            "|[-1.0871530440740...| -0.999478916838796|\n",
            "|[-1.0895105867063...|-0.9959519473039415|\n",
            "|[-1.0305517342706...|-1.0000454254039726|\n",
            "|[-1.0311640824001...|-0.9966920590642687|\n",
            "|[-1.0476974663405...|-0.9767180671187524|\n",
            "|[-1.0589748556868...|-0.9854532578634487|\n",
            "|[-1.0609241610470...|-1.0065968149804025|\n",
            "|[-1.0655678075115...|-0.9929092393134547|\n",
            "|[-1.0550048061662...|-0.9941244895362474|\n",
            "|[-1.0540046318503...|-0.9970484024648409|\n",
            "|[-1.0489936013997...|-1.0008403592259263|\n",
            "|[-1.0595667927306...|-1.0020921574898034|\n",
            "+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHPOV0LUrzt9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}